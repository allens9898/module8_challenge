{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files have been exported successfully.\n",
      "wiki_movies is created.\n",
      "wiki_movies_df is created.\n",
      "wiki_movies_df is cleaned.\n",
      "wiki_movies_df is updated.\n",
      "step1 is done\n",
      "step2 is done\n",
      "step3 is done\n",
      "step4 is done\n",
      "Files have been transformed successfully.\n",
      "6051 Record deleted successfully from movies\n",
      "COMPLETE. Record deleted successfully from movies\n",
      "26024289 Record deleted successfully from ratings\n",
      "COMPLETE. Record deleted successfully from ratings\n",
      "importing rows 0 to 1000000..."
     ]
    }
   ],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import re\n",
    "from sqlalchemy import create_engine\n",
    "import psycopg2\n",
    "from config import db_password\n",
    "import time\n",
    "\n",
    "file_dir = '/Users/all3n8h1h/Desktop/module8_challenge'\n",
    "\n",
    "file_1 = 'wikipedia-movies.json'\n",
    "file_2 = 'movies_metadata.csv'\n",
    "file_3 = 'ratings.csv'\n",
    "\n",
    "def new_files_to_load(wiki_file,kaggle_file,ratings):\n",
    "    with open(f'{file_dir}/{wiki_file}', mode='r') as file:\n",
    "        wiki_movies_raw = json.load(file)\n",
    "    kaggle_metadata = pd.read_csv(f'{file_dir}/{kaggle_file}', low_memory=False)\n",
    "    ratings = pd.read_csv(f'{file_dir}/{ratings}', low_memory=False)\n",
    "    print('Files have been exported successfully.')   \n",
    "    wiki_movies = [movie for movie in wiki_movies_raw if ('Director' in movie or 'Directed by' in movie)\n",
    "                   and 'imdb_link' in movie\n",
    "                   and 'No. of episodes' not in movie]\n",
    "    print('wiki_movies is created.') \n",
    "        wiki_movies_df = pd.DataFrame(wiki_movies)\n",
    "    print('wiki_movies_df is created.') \n",
    "    \n",
    "    def clean_movie(movie):\n",
    "        movie = dict(movie) \n",
    "        alt_titles = {}\n",
    "        for key in ['Also known as','Arabic','Cantonese','Chinese','French',\n",
    "                    'Hangul','Hebrew','Hepburn','Japanese','Literally',\n",
    "                    'Mandarin','McCune-Reischauer','Original title','Polish',\n",
    "                    'Revised Romanization','Romanized','Russian',\n",
    "                    'Simplified','Traditional','Yiddish']:\n",
    "            if key in movie:\n",
    "                alt_titles[key] = movie[key]\n",
    "                movie.pop(key)\n",
    "        if len(alt_titles) > 0:\n",
    "            movie['alt_titles'] = alt_titles\n",
    "\n",
    "        def change_column_name(old_name, new_name):\n",
    "            if old_name in movie:\n",
    "                movie[new_name] = movie.pop(old_name)\n",
    "        change_column_name('Adaptation by', 'Writer(s)')\n",
    "        change_column_name('Country of origin', 'Country')\n",
    "        change_column_name('Directed by', 'Director')\n",
    "        change_column_name('Distributed by', 'Distributor')\n",
    "        change_column_name('Edited by', 'Editor(s)')\n",
    "        change_column_name('Length', 'Running time')\n",
    "        change_column_name('Original release', 'Release date')\n",
    "        change_column_name('Music by', 'Composer(s)')\n",
    "        change_column_name('Produced by', 'Producer(s)')\n",
    "        change_column_name('Producer', 'Producer(s)')\n",
    "        change_column_name('Productioncompanies ', 'Production company(s)')\n",
    "        change_column_name('Productioncompany ', 'Production company(s)')\n",
    "        change_column_name('Released', 'Release Date')\n",
    "        change_column_name('Release Date', 'Release date')\n",
    "        change_column_name('Screen story by', 'Writer(s)')\n",
    "        change_column_name('Screenplay by', 'Writer(s)')\n",
    "        change_column_name('Story by', 'Writer(s)')\n",
    "        change_column_name('Theme music composer', 'Composer(s)')\n",
    "        change_column_name('Written by', 'Writer(s)')\n",
    "\n",
    "        return movie\n",
    "\n",
    "    clean_movies = [clean_movie(movie) for movie in wiki_movies]\n",
    "    wiki_movies_df = pd.DataFrame(clean_movies)\n",
    "    print('wiki_movies_df is cleaned.')\n",
    "        \n",
    "    wiki_movies_df['imdb_id'] = wiki_movies_df['imdb_link'].str.extract(r'(tt\\d{7})')\n",
    "    wiki_movies_df.drop_duplicates(subset='imdb_id', inplace=True)\n",
    "    \n",
    "    wiki_columns_to_keep = [column for column in wiki_movies_df.columns if wiki_movies_df[column].isnull().sum() < len(wiki_movies_df) * 0.9]\n",
    "    wiki_movies_df = wiki_movies_df[wiki_columns_to_keep]\n",
    "    print('wiki_movies_df is updated.')   \n",
    "        \n",
    "    box_office = wiki_movies_df['Box office'].dropna()\n",
    "    budget = wiki_movies_df['Budget'].dropna()\n",
    "        \n",
    "    box_office = box_office.apply(lambda x: ' '.join(x) if type(x) == list else x)\n",
    "    budget = budget.map(lambda x: ' '.join(x) if type(x) == list else x)\n",
    "    release_date = wiki_movies_df['Release date'].dropna().apply(lambda x: ' '.join(x) if type(x) == list else x)\n",
    "    running_time = wiki_movies_df['Running time'].dropna().apply(lambda x: ' '.join(x) if type(x) == list else x)\n",
    "        \n",
    "    form_one = r'\\$\\s*\\d+\\.?\\d*\\s*[mb]illi?on'\n",
    "    form_two = r'\\$\\s*\\d{1,3}(?:[,\\.]\\d{3})+(?!\\s[mb]illion)'\n",
    "    date_form_one = r'(?:January|February|March|April|May|June|July|August|September|October|November|December)\\s[123]\\d,\\s\\d{4}'\n",
    "    date_form_two = r'\\d{4}.[01]\\d.[123]\\d'\n",
    "    date_form_three = r'(?:January|February|March|April|May|June|July|August|September|October|November|December)\\s\\d{4}'\n",
    "    date_form_four = r'\\d{4}'\n",
    "    box_office = box_office.str.replace(r'\\$.*[-—–](?![a-z])', '$', regex=True)\n",
    "    budget = budget.str.replace(r'\\$.*[-—–](?![a-z])', '$', regex=True)\n",
    "    budget = budget.str.replace(r'\\[\\d+\\]\\s*', '')\n",
    "    running_time_extract = running_time.str.extract(r'(\\d+)\\s*ho?u?r?s?\\s*(\\d*)|(\\d+)\\s*m')\n",
    "    running_time_extract = running_time_extract.apply(lambda col: pd.to_numeric(col, errors='coerce')).fillna(0)\n",
    "        \n",
    "    def parse_dollars(s):\n",
    "        \n",
    "        if type(s) != str:\n",
    "            return np.nan\n",
    "\n",
    "        if re.match(r'\\$\\s*\\d+\\.?\\d*\\s*milli?on', s, flags=re.IGNORECASE):\n",
    "            s = re.sub('\\$|\\s|[a-zA-Z]','', s)\n",
    "            value = float(s) * 10**6\n",
    "            return value\n",
    "\n",
    "        elif re.match(r'\\$\\s*\\d+\\.?\\d*\\s*billi?on', s, flags=re.IGNORECASE):\n",
    "            s = re.sub('\\$|\\s|[a-zA-Z]','', s)\n",
    "            value = float(s) * 10**9\n",
    "            return value\n",
    "\n",
    "        elif re.match(r'\\$\\s*\\d{1,3}(?:[,\\.]\\d{3})+(?!\\s[mb]illion)', s, flags=re.IGNORECASE):\n",
    "            s = re.sub('\\$|,','', s)\n",
    "            value = float(s)\n",
    "            return value\n",
    "\n",
    "        else:\n",
    "            return np.nan\n",
    "        \n",
    "    wiki_movies_df['box_office'] = box_office.str.extract(f'({form_one}|{form_two})', flags=re.IGNORECASE)[0].apply(parse_dollars)\n",
    "    wiki_movies_df['budget'] = budget.str.extract(f'({form_one}|{form_two})', flags=re.IGNORECASE)[0].apply(parse_dollars)\n",
    "    wiki_movies_df['release_date'] = pd.to_datetime(release_date.str.extract(f'({date_form_one}|{date_form_two}|{date_form_three}|{date_form_four})')[0], infer_datetime_format=True)\n",
    "    wiki_movies_df['running_time'] = running_time_extract.apply(lambda row: row[0]*60 + row[1] if row[2] == 0 else row[2], axis=1)\n",
    "       \n",
    "    wiki_movies_df.drop('Box office', axis=1, inplace=True)\n",
    "    wiki_movies_df.drop('Budget', axis=1, inplace=True)\n",
    "    wiki_movies_df.drop('Release date', axis=1, inplace=True)\n",
    "    wiki_movies_df.drop('Running time', axis=1, inplace=True)\n",
    "    print('step1 is done')\n",
    "    \n",
    "\n",
    "    kaggle_metadata = kaggle_metadata[kaggle_metadata['adult'] == 'False'].drop('adult',axis='columns')\n",
    "        \n",
    "    kaggle_metadata['video'] = kaggle_metadata['video'] == 'True'\n",
    "        \n",
    "    kaggle_metadata['budget'] = kaggle_metadata['budget'].astype(int)\n",
    "    kaggle_metadata['id'] = pd.to_numeric(kaggle_metadata['id'], errors='raise')\n",
    "    kaggle_metadata['popularity'] = pd.to_numeric(kaggle_metadata['popularity'], errors='raise')\n",
    "        \n",
    "    kaggle_metadata['release_date'] = pd.to_datetime(kaggle_metadata['release_date'])\n",
    "        \n",
    "    ratings['timestamp'] = pd.to_datetime(ratings['timestamp'], unit='s')\n",
    "    print('step2 is done') \n",
    "    \n",
    "    movies_df = pd.merge(wiki_movies_df, kaggle_metadata, on='imdb_id', suffixes=['_wiki','_kaggle'])\n",
    "        \n",
    "    try:\n",
    "        movies_df = movies_df.drop(movies_df[(movies_df['release_date_wiki'] > '1996-01-01') & (movies_df['release_date_kaggle'] < '1965-01-01')].index)\n",
    "    except:\n",
    "        print('No rows to drop because of data corruption')\n",
    "            \n",
    "    movies_df.drop(columns=['title_wiki','release_date_wiki','Language','Production company(s)'], inplace=True)\n",
    "\n",
    "    def fill_missing_kaggle_data(df, kaggle_column, wiki_column):\n",
    "        df[kaggle_column] = df.apply(\n",
    "            lambda row: row[wiki_column] if row[kaggle_column] == 0 else row[kaggle_column], axis=1)\n",
    "        df.drop(columns=wiki_column, inplace=True)\n",
    "          \n",
    "    fill_missing_kaggle_data(movies_df, 'runtime', 'running_time')\n",
    "    fill_missing_kaggle_data(movies_df, 'budget_kaggle', 'budget_wiki')\n",
    "    fill_missing_kaggle_data(movies_df, 'revenue', 'box_office')\n",
    "        \n",
    "    try:\n",
    "        for col in movies_df.columns:\n",
    "            lists_to_tuples = lambda x: tuple(x) if type(x) == list else x\n",
    "            value_counts = movies_df[col].apply(lists_to_tuples).value_counts(dropna=False)\n",
    "            num_values = len(value_counts)\n",
    "            if num_values == 1:\n",
    "                movies_df.drop(col, axis=1, inplace=True)\n",
    "    except:\n",
    "        print('No columns to drop because of only one value')\n",
    "        \n",
    "    movies_df = movies_df[['imdb_id','id','title_kaggle','original_title','tagline','belongs_to_collection','url','imdb_link',\n",
    "                       'runtime','budget_kaggle','revenue','release_date_kaggle','popularity','vote_average','vote_count',\n",
    "                       'genres','original_language','overview','spoken_languages','Country',\n",
    "                       'production_companies','production_countries','Distributor',\n",
    "                       'Producer(s)','Director','Starring','Cinematography','Editor(s)','Writer(s)','Composer(s)','Based on'\n",
    "                      ]]\n",
    "    movies_df.rename({'id':'kaggle_id',\n",
    "                  'title_kaggle':'title',\n",
    "                  'url':'wikipedia_url',\n",
    "                  'budget_kaggle':'budget',\n",
    "                  'release_date_kaggle':'release_date',\n",
    "                  'Country':'country',\n",
    "                  'Distributor':'distributor',\n",
    "                  'Producer(s)':'producers',\n",
    "                  'Director':'director',\n",
    "                  'Starring':'starring',\n",
    "                  'Cinematography':'cinematography',\n",
    "                  'Editor(s)':'editors',\n",
    "                  'Writer(s)':'writers',\n",
    "                  'Composer(s)':'composers',\n",
    "                  'Based on':'based_on'\n",
    "                 }, axis='columns', inplace=True)\n",
    "    print('step3 is done')     \n",
    "        \n",
    "\n",
    "    rating_counts = ratings.groupby(['movieId','rating'], as_index=False).count()\n",
    "\n",
    "\n",
    "    rating_counts = rating_counts.rename({'userId':'count'}, axis=1) \n",
    "\n",
    "    rating_counts = rating_counts.pivot(index='movieId',columns='rating', values='count')\n",
    "\n",
    "    rating_counts.columns = ['rating_' + str(col) for col in rating_counts.columns]\n",
    "        \n",
    "    movies_with_ratings_df = pd.merge(movies_df, rating_counts, left_on='kaggle_id', right_index=True, how='left')\n",
    "\n",
    "    movies_with_ratings_df[rating_counts.columns] = movies_with_ratings_df[rating_counts.columns].fillna(0)\n",
    "    print('step4 is done')    \n",
    "    print('Files have been transformed successfully.')\n",
    "        \n",
    "    db_string = f\"postgres://postgres:{db_password}@127.0.0.1:5432/movie_data\"\n",
    "\n",
    "    engine = create_engine(db_string)\n",
    "    try:\n",
    "        connection = psycopg2.connect(db_string)\n",
    "        cursor = connection.cursor()\n",
    "        sql_delete_query = \"DELETE FROM movies\"\n",
    "        cursor.execute(sql_delete_query)\n",
    "        connection.commit()\n",
    "        count = cursor.rowcount\n",
    "        print(count, \"Record deleted successfully from movies\")\n",
    "\n",
    "    except (Exception, psycopg2.Error) as error:\n",
    "        print(\"Record from movies deleted. Complete.\")\n",
    "    \n",
    "    print(\"COMPLETE. Record deleted successfully from movies\")    \n",
    "    \n",
    "    try:\n",
    "        connection = psycopg2.connect(db_string)\n",
    "        cursor = connection.cursor()\n",
    "        sql_delete_query = \"DELETE FROM ratings\"\n",
    "        cursor.execute(sql_delete_query)\n",
    "        connection.commit()\n",
    "        count = cursor.rowcount\n",
    "        print(count, \"Record deleted successfully from ratings\")\n",
    "\n",
    "    except (Exception, psycopg2.Error) as error:\n",
    "        print(\"Error in Delete operation\", error)\n",
    "            \n",
    "    print(\"COMPLETE. Record deleted successfully from ratings\")   \n",
    "    \n",
    "    movies_df.to_sql(name='movies', con=engine, if_exists='append')\n",
    "        \n",
    "    \n",
    "    rows_imported = 0\n",
    "    start_time = time.time()\n",
    "    for data in pd.read_csv(f'{file_dir}/ratings.csv', chunksize=1000000):\n",
    "        print(f'importing rows {rows_imported} to {rows_imported + len(data)}...', end='')\n",
    "        data.to_sql(name='ratings', con=engine, if_exists='append')\n",
    "        rows_imported += len(data)\n",
    "        print(f'Done. {time.time() - start_time} total seconds elapsed')\n",
    "\n",
    "    print('step5 is done') \n",
    "    print('Files have been updated and loaded successfully.')\n",
    "\n",
    "new_files_to_load(file_1,file_2,file_3)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
